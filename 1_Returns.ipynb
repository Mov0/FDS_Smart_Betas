{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('RawData/Returns.csv', index_col=\"RIC\")\n",
    "data.columns = pd.to_datetime(data.columns, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows have not the expected data type float64. Perfect!\n"
     ]
    }
   ],
   "source": [
    "# Check if all rows only contain numbers (or NaNs)\n",
    "n = 0\n",
    "for type in data.dtypes.values:\n",
    "    if type.name != \"float64\":\n",
    "        n += 1\n",
    "if(n == 0):\n",
    "    print(f\"{n} rows have not the expected data type float64. Perfect!\")\n",
    "else:\n",
    "    print(f\"{n} rows dont have the expected data type float64. Check carefully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section runs the filter proposed by Ince & Porter 2006. As this leaves many extreme returns in the dataframe, we just exlude returns > 100%. So dont run the next two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extremes = data[data[data.columns[1:]] > 300]\n",
    "# extremes.dropna(axis = 0, how = 'all', inplace = True)\n",
    "# extremes.dropna(axis = 1, how = 'all', inplace = True)\n",
    "# print(f\"The return data contains {extremes.count().sum()} entries where the monthly return was above 300 %. These data points could be errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell iterates through all the extreme positiv (return > 300 %) and checks if there are extreme negative returns the month befor or after so that the gains are almost completely compensated. In that chase there was probably a wrong price reported for the stock in that month and therefore wrong returns have been calculated. These retruns are set to NaN.\n",
    "# # The errors dataframe collected all the detected values as well as the return from the prio/next month. It was used for getting an overview over the data but is not necessary for further work.\n",
    "\n",
    "# extreme_count = 0\n",
    "# nan_count = 0\n",
    "# cleaned_data = data.copy(deep=True)\n",
    "# # errors = DataFrame.copy(extremes).drop(extremes.index)\n",
    "# for ric in extremes.index:\n",
    "#     for extreme_date in extremes.columns:\n",
    "#         extreme_val = extremes.loc[ric, extreme_date]\n",
    "#         if not np.isnan(extreme_val):\n",
    "#             prior_date = data.columns[data.columns.get_loc(extreme_date)-1]\n",
    "#             prior_val = data.loc[ric, prior_date]\n",
    "#             prior_calc = ((1+extreme_val/100)*(1+prior_val/100)-1)*100\n",
    "\n",
    "#             next_date = data.columns[data.columns.get_loc(extreme_date)+1]\n",
    "#             next_val = data.loc[ric, next_date]\n",
    "#             next_calc = ((1+extreme_val/100)*(1+next_val/100)-1)*100\n",
    "#             if (prior_calc < 50 and next_calc < 50) or (np.isnan(prior_calc) and np.isnan(next_calc)):\n",
    "#                 # errors.at[ric, prior_date] = prior_val\n",
    "#                 # errors.at[ric, extreme_date] = extreme_val\n",
    "#                 # errors.at[ric, next_date] = next_val\n",
    "#                 cleaned_data.at[ric, prior_date] = np.nan\n",
    "#                 cleaned_data.at[ric, extreme_date] = np.nan\n",
    "#                 cleaned_data.at[ric, next_date] = np.nan\n",
    "#                 # print(f\"[{ric}]\\nPrior: {prior_val}   {prior_date}\\nExtreme: {extreme_val}   {extreme_date}\\nNext: {next_val}   {next_date}\")\n",
    "#                 if np.isnan(prior_calc) and np.isnan(next_calc):\n",
    "#                     nan_count += 1\n",
    "#                 else:\n",
    "#                     extreme_count +=1\n",
    "#             elif prior_calc < 50 or np.isnan(prior_calc):\n",
    "#                 # errors.at[ric, prior_date] = prior_val\n",
    "#                 # errors.at[ric, extreme_date] = extreme_val\n",
    "#                 cleaned_data.at[ric, prior_date] = np.nan\n",
    "#                 cleaned_data.at[ric, extreme_date] = np.nan\n",
    "#                 # print(f\"[{ric}]\\nPrior: {prior_val}   {prior_date}\\nExtreme: {extreme_val}   {extreme_date}\\nNext: {next_val}   {next_date}\")\n",
    "#                 if np.isnan(prior_calc):\n",
    "#                     nan_count += 1\n",
    "#                 else:\n",
    "#                     extreme_count +=1\n",
    "#             elif next_calc < 50 or np.isnan(next_calc):\n",
    "#                 # errors.at[ric, extreme_date] = extreme_val\n",
    "#                 # errors.at[ric, next_date] = next_val\n",
    "#                 cleaned_data.at[ric, extreme_date] = np.nan\n",
    "#                 cleaned_data.at[ric, next_date] = np.nan\n",
    "#                 # print(f\"[{ric}]\\nPrior: {prior_val}   {prior_date}\\nExtreme: {extreme_val}   {extreme_date}\\nNext: {next_val}   {next_date}\")\n",
    "#                 if np.isnan(next_calc):\n",
    "#                     nan_count += 1\n",
    "#                 else:\n",
    "#                     extreme_count +=1\n",
    "            \n",
    "# print(f\"{nan_count} periods have been removed due to NaN values in the prior/next period. {extreme_count} periods have been removed due to extreme loss/gain that is compensated in the prior/next period. Both factors indicate errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell instead for a simpler but more effective removal of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-nan returns before outlier removal: 216331\n",
      "1 % of the positive returns are bigger than 145.9016393\n",
      "1 % of the negative returns are smaller than -60.0\n",
      "Number of non-nan returns after outlier removal: 214334\n",
      "Difference: 1997\n"
     ]
    }
   ],
   "source": [
    "# Remove returns that are bigger/smaller than p % of the positive/negative returns\n",
    "\n",
    "from numpy import negative\n",
    "\n",
    "\n",
    "p = 1\n",
    "\n",
    "# Turn dataframe into one dimensional numpy array and remove nans\n",
    "returns = data.to_numpy().flatten()\n",
    "returns = returns[~np.isnan(returns)]\n",
    "n_before = len(returns)\n",
    "positives = returns[returns > 0]\n",
    "negatives = returns[returns < 0]\n",
    "\n",
    "# Calculate boundaries based one perentile\n",
    "lower_boundary = np.percentile(negatives, p)\n",
    "upper_boundary = np.percentile(positives, 100-p)\n",
    "print(f\"Number of non-nan returns before outlier removal: {n_before}\")\n",
    "print(f\"{p} % of the positive returns are bigger than {upper_boundary}\")\n",
    "print(f\"{p} % of the negative returns are smaller than {lower_boundary}\")\n",
    "\n",
    "# Go through columns and remove returns outside of interval (lower_boundary, upper_boundary)\n",
    "cleaned_data = data.copy()\n",
    "for column in data.columns:\n",
    "    c = data[column]\n",
    "    cleaned_data[column] = c[c.between(lower_boundary, upper_boundary)]\n",
    "\n",
    "# Print number of non-nan returns after outlier removal\n",
    "returns = cleaned_data.to_numpy().flatten()\n",
    "returns = returns[~np.isnan(returns)]\n",
    "n_after = len(returns)\n",
    "print(f\"Number of non-nan returns after outlier removal: {n_after}\")\n",
    "print(f\"Difference: {n_before-n_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe\n",
    "cleaned_data.to_pickle(\"UsableData/Returns.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
